{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf4ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from memory_saving_gradients import gradients\n",
    "\n",
    "import colour_demosaicing as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68d2cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(patches, resolutionX):  # Сшивание кусков обратно в изображения\n",
    "    k = -1\n",
    "    for g in range(resolutionX.shape[0]):\n",
    "        dimensions = resolutionX[g]\n",
    "        S = np.zeros((dimensions[0], dimensions[1], 3))\n",
    "        for z in range(0, dimensions[0] - 31, 32):\n",
    "            for j in range(0, dimensions[1] - 31, 32):\n",
    "                k += 1\n",
    "                S[z:z + 32, j:j + 32] = patches[k]\n",
    "        S = S * 255.\n",
    "        cv2.imwrite('/content/drive/MyDrive/abbyy_demosaic/{}.png'.format(g), S)\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "965a6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch(path):  # Получение кусков 32х32 из исходных изображений и сохранение оригинальных размеров\n",
    "    data = None\n",
    "    data = np.zeros((10000, 32, 32, 3))\n",
    "    resolutions = None\n",
    "    patches = 0\n",
    "    files = os.listdir(path)\n",
    "    for name in files:\n",
    "        img = cv2.imread(path + '/' + name)\n",
    "        width = (img.shape[0] // 32) * 32\n",
    "        height = (img.shape[1] // 32) * 32\n",
    "        dimentions = np.array([width, height])\n",
    "        resolutions = dimentions.reshape(1, 2) if (resolutions is None) else np.vstack((resolutions, dimentions.reshape(1, 2)))\n",
    "        for i in range(0, img.shape[0] - 31, 32):\n",
    "            for j in range(0, img.shape[1] - 31, 32):\n",
    "                patch = img[i:i + 32, j:j + 32].reshape(1, 32, 32, 3)\n",
    "                patches += 1\n",
    "                if patches <= data.shape[0]:\n",
    "                    data[patches-1] = patch\n",
    "                else:\n",
    "                    data.resize((patches + 9999, 32, 32, 3))\n",
    "                    data[patches-1] = patch\n",
    "    if patches < data.shape[0]:\n",
    "        data = np.delete(data, np.s_[patches:data.shape[0]], 0)\n",
    "    return data, resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a483f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, sqrt\n",
    "\n",
    "def PSNR(y_true, y_pred):  # Метрика PSNR для тренировки\n",
    "    #max_pixel = 1.0\n",
    "    #return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1))))/ 2.303\n",
    "\n",
    "    mse = K.mean(K.square(y_pred - y_true))\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100.0\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * tf.experimental.numpy.log10(max_pixel / tf.math.sqrt(mse))\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aba6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(data_array):  # Мозайка исходных изображений для тренировки\n",
    "    mosaic_array = np.copy(data_array)\n",
    "    for picture in mosaic_array:\n",
    "        bayer = cd.mosaicing_CFA_Bayer(picture, pattern='GBRG')\n",
    "        bayer = cv2.cvtColor(np.float32(bayer), cv2.COLOR_GRAY2BGR)  # Convert from Grayscale to BGR (r=g=b for each pixel).\n",
    "        bayer[0::2, 0::2, 0::2] = 0  # Green pixels - set the blue and the red planes to zero (and keep the green)\n",
    "        bayer[0::2, 1::2, 0:2] = 0   # Red pixels - set the blue and the green planes to zero (and keep the red)\n",
    "        bayer[1::2, 0::2, 1:] = 0    # Blue pixels - set the red and the green planes to zero (and keep the blue)\n",
    "        bayer[1::2, 1::2, 0::2] = 0  # Green pixels - set the blue and the red planes to zero (and keep the green)\n",
    "\n",
    "    return mosaic_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ed39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,             # Генератор кусков для модели\n",
    "                             samplewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             samplewise_std_normalization=False,\n",
    "                             zca_whitening=False,\n",
    "                             zca_epsilon=1e-06,\n",
    "                             rotation_range=90,\n",
    "                             width_shift_range=0.0,\n",
    "                             height_shift_range=0.0,\n",
    "                             brightness_range=None,\n",
    "                             shear_range=0.0,\n",
    "                             zoom_range=0.0,\n",
    "                             channel_shift_range=0.0,\n",
    "                             fill_mode='nearest',\n",
    "                             cval=0.0,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             rescale=1/255.,\n",
    "                             preprocessing_function=None,\n",
    "                             data_format=\"channels_last\",\n",
    "                             validation_split=0.05,\n",
    "                             dtype=None)\n",
    "\n",
    "\n",
    "def train_generator(X, Xi, Y, batch_size):\n",
    "    genX1 = datagen.flow(X, y=None,  batch_size=batch_size, seed=47, subset=\"training\")\n",
    "    genX2 = datagen.flow(Xi, y=None, batch_size=batch_size, seed=47, subset=\"training\")\n",
    "    genY = datagen.flow(Y, y=None, batch_size=batch_size, seed=47, subset=\"training\")\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        Yi = genY.next()\n",
    "        X_batch = [X1i, X2i]\n",
    "        Y_batch = Yi\n",
    "        yield X_batch, Y_batch\n",
    "\n",
    "\n",
    "def valid_generator(X, Xi, Y, batch_size):\n",
    "    genX1 = datagen.flow(X, y=None,  batch_size=batch_size, seed=47, subset=\"validation\")\n",
    "    genX2 = datagen.flow(Xi, y=None, batch_size=batch_size, seed=47, subset=\"validation\")\n",
    "    genY = datagen.flow(Y, y=None, batch_size=batch_size, seed=47, subset=\"validation\")\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        Yi = genY.next()\n",
    "        X_batch = [X1i, X2i]\n",
    "        Y_batch = Yi\n",
    "        yield X_batch, Y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94a25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ячейка для генерации датасетов из октрытого набора изображений Flickr500\n",
    "import os\n",
    "directory = './testing_dataset/Y'\n",
    " \n",
    "for filename in os.listdir(directory):\n",
    "    img = cv2.imread(directory + '/' + filename)\n",
    "    img = cd.mosaicing_CFA_Bayer(img, pattern='GBRG')\n",
    "    bayer = cv2.cvtColor(np.float32(img), cv2.COLOR_GRAY2BGR) \n",
    "    bayer[0::2, 0::2, 0::2] = 0 \n",
    "    bayer[0::2, 1::2, 0:2] = 0   \n",
    "    bayer[1::2, 0::2, 1:] = 0    \n",
    "    bayer[1::2, 1::2, 0::2] = 0  \n",
    "    \n",
    "    img = cd.demosaicing_CFA_Bayer_bilinear(img, pattern='GBRG')\n",
    "    \n",
    "    cv2.imwrite('./testing_dataset/Xi/' + filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac663b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ячейка для оцени размера модели (честно взята из интернета)\n",
    "\n",
    "def keras_model_memory_usage_in_bytes(model, *, batch_size: int):\n",
    "    \"\"\"\n",
    "    Return the estimated memory usage of a given Keras model in bytes.\n",
    "    This includes the model weights and layers, but excludes the dataset.\n",
    "\n",
    "    The model shapes are multipled by the batch size, but the weights are not.\n",
    "\n",
    "    Args:\n",
    "        model: A Keras model.\n",
    "        batch_size: The batch size you intend to run the model with. If you\n",
    "            have already specified the batch size in the model itself, then\n",
    "            pass `1` as the argument here.\n",
    "    Returns:\n",
    "        An estimate of the Keras model's memory usage in bytes.\n",
    "\n",
    "    \"\"\"\n",
    "    default_dtype = tf.keras.backend.floatx()\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            internal_model_mem_count += keras_model_memory_usage_in_bytes(\n",
    "                layer, batch_size=batch_size\n",
    "            )\n",
    "        single_layer_mem = tf.as_dtype(layer.dtype or default_dtype).size\n",
    "        out_shape = layer.output_shape\n",
    "        if isinstance(out_shape, list):\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = sum(\n",
    "        [tf.keras.backend.count_params(p) for p in model.trainable_weights]\n",
    "    )\n",
    "    non_trainable_count = sum(\n",
    "        [tf.keras.backend.count_params(p) for p in model.non_trainable_weights]\n",
    "    )\n",
    "\n",
    "    total_memory = (\n",
    "        batch_size * shapes_mem_count\n",
    "        + internal_model_mem_count\n",
    "        + trainable_count\n",
    "        + non_trainable_count\n",
    "    )\n",
    "    return total_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f60c2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20  # кол-во слоев\n",
    "# Описание модели\n",
    "inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "Xinter = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=128,\n",
    "                           kernel_size=3,\n",
    "                           padding=\"same\",\n",
    "                           data_format=\"channels_last\")(inputs)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
    "\n",
    "x = keras.layers.Activation(\"selu\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "for i in range(N - 1):\n",
    "    x = keras.layers.Conv2D(filters=128,\n",
    "                            kernel_size=3,\n",
    "                            padding=\"same\",\n",
    "                            data_format=\"channels_last\")(x)\n",
    "    x = keras.layers.BatchNormalization(axis=-1, )(x)\n",
    "    x = keras.layers.Activation(\"selu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(filters=3, kernel_size=3, padding=\"same\")(x)\n",
    "\n",
    "output = keras.layers.Add()([x, Xinter])\n",
    "\n",
    "model = keras.Model(inputs=[inputs, Xinter], outputs=output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[PSNR])\n",
    "filepath = \"./weights/saved-model-{epoch:02d}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_PSNR', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3707cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2540924577\n"
     ]
    }
   ],
   "source": [
    "print(keras_model_memory_usage_in_bytes(model=model, batch_size=32) / 1024 / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathY = './testing_dataset/Y/'\n",
    "pathXi = './testing_dataset/Xi'\n",
    "Ytemp, resolution = patch(pathY)\n",
    "Y = np.copy(Ytemp)\n",
    "Ytemp = None\n",
    "print(\"Y is ready\")\n",
    "X = mosaic(Y)\n",
    "print(\"X is ready\")\n",
    "Xitemp, resolution = patch(pathXi)\n",
    "Xi = np.copy(Xitemp)\n",
    "Xitemp = None\n",
    "print(\"Xi is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "038af5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3210/3210 [==============================] - 145s 43ms/step - loss: 0.0215 - PSNR: 23.2940 - val_loss: 0.0060 - val_PSNR: 22.4167\n",
      "\n",
      "Epoch 00001: val_PSNR improved from -inf to 22.41672, saving model to C:/Users/vergi/Documents/weights\\saved-model-01.hdf5\n",
      "Epoch 2/100\n",
      "   1/3210 [..............................] - ETA: 2:13 - loss: 0.0016 - PSNR: 27.9816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vergi\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210/3210 [==============================] - 139s 43ms/step - loss: 0.0033 - PSNR: 30.3678 - val_loss: 590.9568 - val_PSNR: -27.4919\n",
      "\n",
      "Epoch 00002: val_PSNR did not improve from 22.41672\n",
      "Epoch 3/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 0.0011 - PSNR: 30.0658 - val_loss: 8.8834e-04 - val_PSNR: 30.6076\n",
      "\n",
      "Epoch 00003: val_PSNR improved from 22.41672 to 30.60757, saving model to C:/Users/vergi/Documents/weights\\saved-model-03.hdf5\n",
      "Epoch 4/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 8.4157e-04 - PSNR: 31.0045 - val_loss: 0.0010 - val_PSNR: 30.2248\n",
      "\n",
      "Epoch 00004: val_PSNR did not improve from 30.60757\n",
      "Epoch 5/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 0.0025 - PSNR: 30.0873 - val_loss: 0.0011 - val_PSNR: 29.6194\n",
      "\n",
      "Epoch 00005: val_PSNR did not improve from 30.60757\n",
      "Epoch 6/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 0.0013 - PSNR: 30.4957 - val_loss: 8.2293e-04 - val_PSNR: 30.9601\n",
      "\n",
      "Epoch 00006: val_PSNR improved from 30.60757 to 30.96010, saving model to C:/Users/vergi/Documents/weights\\saved-model-06.hdf5\n",
      "Epoch 7/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 8.2414e-04 - PSNR: 31.0959 - val_loss: 8.2169e-04 - val_PSNR: 30.9601\n",
      "\n",
      "Epoch 00007: val_PSNR did not improve from 30.96010\n",
      "Epoch 8/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 0.0021 - PSNR: 29.6921 - val_loss: 0.0014 - val_PSNR: 28.6588\n",
      "\n",
      "Epoch 00008: val_PSNR did not improve from 30.96010\n",
      "Epoch 9/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 9.6392e-04 - PSNR: 30.4097 - val_loss: 9.6300e-04 - val_PSNR: 30.2472\n",
      "\n",
      "Epoch 00009: val_PSNR did not improve from 30.96010\n",
      "Epoch 10/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 8.6953e-04 - PSNR: 30.8428 - val_loss: 8.3585e-04 - val_PSNR: 30.8708\n",
      "\n",
      "Epoch 00010: val_PSNR did not improve from 30.96010\n",
      "Epoch 11/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 8.1417e-04 - PSNR: 31.1647 - val_loss: 8.2326e-04 - val_PSNR: 30.9521\n",
      "\n",
      "Epoch 00011: val_PSNR did not improve from 30.96010\n",
      "Epoch 12/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 7.9916e-04 - PSNR: 31.2404 - val_loss: 7.9509e-04 - val_PSNR: 31.1271\n",
      "\n",
      "Epoch 00012: val_PSNR improved from 30.96010 to 31.12712, saving model to C:/Users/vergi/Documents/weights\\saved-model-12.hdf5\n",
      "Epoch 13/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 6.9411e-04 - PSNR: 31.8593 - val_loss: 6.4650e-04 - val_PSNR: 31.9980\n",
      "\n",
      "Epoch 00013: val_PSNR improved from 31.12712 to 31.99804, saving model to C:/Users/vergi/Documents/weights\\saved-model-13.hdf5\n",
      "Epoch 14/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 6.0103e-04 - PSNR: 32.4537 - val_loss: 6.0103e-04 - val_PSNR: 32.3012\n",
      "\n",
      "Epoch 00014: val_PSNR improved from 31.99804 to 32.30125, saving model to C:/Users/vergi/Documents/weights\\saved-model-14.hdf5\n",
      "Epoch 15/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.8653e-04 - PSNR: 32.5531 - val_loss: 5.9310e-04 - val_PSNR: 32.3834\n",
      "\n",
      "Epoch 00015: val_PSNR improved from 32.30125 to 32.38345, saving model to C:/Users/vergi/Documents/weights\\saved-model-15.hdf5\n",
      "Epoch 16/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.7446e-04 - PSNR: 32.6400 - val_loss: 5.9187e-04 - val_PSNR: 32.3739\n",
      "\n",
      "Epoch 00016: val_PSNR did not improve from 32.38345\n",
      "Epoch 17/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.7497e-04 - PSNR: 32.6378 - val_loss: 5.8679e-04 - val_PSNR: 32.4247\n",
      "\n",
      "Epoch 00017: val_PSNR improved from 32.38345 to 32.42467, saving model to C:/Users/vergi/Documents/weights\\saved-model-17.hdf5\n",
      "Epoch 18/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.6970e-04 - PSNR: 32.6791 - val_loss: 5.8736e-04 - val_PSNR: 32.4302\n",
      "\n",
      "Epoch 00018: val_PSNR improved from 32.42467 to 32.43015, saving model to C:/Users/vergi/Documents/weights\\saved-model-18.hdf5\n",
      "Epoch 19/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.6704e-04 - PSNR: 32.6947 - val_loss: 6.0693e-04 - val_PSNR: 32.2640\n",
      "\n",
      "Epoch 00019: val_PSNR did not improve from 32.43015\n",
      "Epoch 20/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.6377e-04 - PSNR: 32.7229 - val_loss: 5.9508e-04 - val_PSNR: 32.3684\n",
      "\n",
      "Epoch 00020: val_PSNR did not improve from 32.43015\n",
      "Epoch 21/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.6280e-04 - PSNR: 32.7304 - val_loss: 5.8785e-04 - val_PSNR: 32.4186\n",
      "\n",
      "Epoch 00021: val_PSNR did not improve from 32.43015\n",
      "Epoch 22/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.5447e-04 - PSNR: 32.8043 - val_loss: 5.8782e-04 - val_PSNR: 32.4089\n",
      "\n",
      "Epoch 00022: val_PSNR did not improve from 32.43015\n",
      "Epoch 23/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.5956e-04 - PSNR: 32.7552 - val_loss: 5.8131e-04 - val_PSNR: 32.4677\n",
      "\n",
      "Epoch 00023: val_PSNR improved from 32.43015 to 32.46772, saving model to C:/Users/vergi/Documents/weights\\saved-model-23.hdf5\n",
      "Epoch 24/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.5510e-04 - PSNR: 32.7904 - val_loss: 5.8227e-04 - val_PSNR: 32.4602\n",
      "\n",
      "Epoch 00024: val_PSNR did not improve from 32.46772\n",
      "Epoch 25/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.5469e-04 - PSNR: 32.7951 - val_loss: 5.8631e-04 - val_PSNR: 32.4250\n",
      "\n",
      "Epoch 00025: val_PSNR did not improve from 32.46772\n",
      "Epoch 26/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 5.1936e-04 - PSNR: 33.0723 - val_loss: 5.3452e-04 - val_PSNR: 32.8314\n",
      "\n",
      "Epoch 00026: val_PSNR improved from 32.46772 to 32.83138, saving model to C:/Users/vergi/Documents/weights\\saved-model-26.hdf5\n",
      "Epoch 27/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.9504e-04 - PSNR: 33.2663 - val_loss: 5.0419e-04 - val_PSNR: 33.0697\n",
      "\n",
      "Epoch 00027: val_PSNR improved from 32.83138 to 33.06968, saving model to C:/Users/vergi/Documents/weights\\saved-model-27.hdf5\n",
      "Epoch 28/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.8867e-04 - PSNR: 33.3299 - val_loss: 5.0094e-04 - val_PSNR: 33.1296\n",
      "\n",
      "Epoch 00028: val_PSNR improved from 33.06968 to 33.12963, saving model to C:/Users/vergi/Documents/weights\\saved-model-28.hdf5\n",
      "Epoch 29/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7889e-04 - PSNR: 33.4242 - val_loss: 4.9413e-04 - val_PSNR: 33.1851\n",
      "\n",
      "Epoch 00029: val_PSNR improved from 33.12963 to 33.18514, saving model to C:/Users/vergi/Documents/weights\\saved-model-29.hdf5\n",
      "Epoch 30/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7895e-04 - PSNR: 33.4221 - val_loss: 4.9495e-04 - val_PSNR: 33.1604\n",
      "\n",
      "Epoch 00030: val_PSNR did not improve from 33.18514\n",
      "Epoch 31/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7411e-04 - PSNR: 33.4599 - val_loss: 4.8753e-04 - val_PSNR: 33.2225\n",
      "\n",
      "Epoch 00031: val_PSNR improved from 33.18514 to 33.22250, saving model to C:/Users/vergi/Documents/weights\\saved-model-31.hdf5\n",
      "Epoch 32/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7025e-04 - PSNR: 33.4953 - val_loss: 4.9124e-04 - val_PSNR: 33.2038\n",
      "\n",
      "Epoch 00032: val_PSNR did not improve from 33.22250\n",
      "Epoch 33/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7438e-04 - PSNR: 33.4646 - val_loss: 4.9057e-04 - val_PSNR: 33.1885\n",
      "\n",
      "Epoch 00033: val_PSNR did not improve from 33.22250\n",
      "Epoch 34/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.7147e-04 - PSNR: 33.4887 - val_loss: 5.0808e-04 - val_PSNR: 33.0693\n",
      "\n",
      "Epoch 00034: val_PSNR did not improve from 33.22250\n",
      "Epoch 35/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6484e-04 - PSNR: 33.5439 - val_loss: 4.9577e-04 - val_PSNR: 33.1493\n",
      "\n",
      "Epoch 00035: val_PSNR did not improve from 33.22250\n",
      "Epoch 36/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6785e-04 - PSNR: 33.5255 - val_loss: 4.9679e-04 - val_PSNR: 33.1577\n",
      "\n",
      "Epoch 00036: val_PSNR did not improve from 33.22250\n",
      "Epoch 37/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6280e-04 - PSNR: 33.5684 - val_loss: 4.9591e-04 - val_PSNR: 33.1528\n",
      "\n",
      "Epoch 00037: val_PSNR did not improve from 33.22250\n",
      "Epoch 38/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6580e-04 - PSNR: 33.5389 - val_loss: 4.8970e-04 - val_PSNR: 33.2193\n",
      "\n",
      "Epoch 00038: val_PSNR did not improve from 33.22250\n",
      "Epoch 39/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6392e-04 - PSNR: 33.5615 - val_loss: 4.8903e-04 - val_PSNR: 33.2260\n",
      "\n",
      "Epoch 00039: val_PSNR improved from 33.22250 to 33.22599, saving model to C:/Users/vergi/Documents/weights\\saved-model-39.hdf5\n",
      "Epoch 40/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6263e-04 - PSNR: 33.5728 - val_loss: 5.0323e-04 - val_PSNR: 33.0938\n",
      "\n",
      "Epoch 00040: val_PSNR did not improve from 33.22599\n",
      "Epoch 41/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6079e-04 - PSNR: 33.5794 - val_loss: 4.8998e-04 - val_PSNR: 33.2359\n",
      "\n",
      "Epoch 00041: val_PSNR improved from 33.22599 to 33.23593, saving model to C:/Users/vergi/Documents/weights\\saved-model-41.hdf5\n",
      "Epoch 42/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5659e-04 - PSNR: 33.6142 - val_loss: 5.0497e-04 - val_PSNR: 33.0792\n",
      "\n",
      "Epoch 00042: val_PSNR did not improve from 33.23593\n",
      "Epoch 43/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5936e-04 - PSNR: 33.5904 - val_loss: 4.8202e-04 - val_PSNR: 33.2706\n",
      "\n",
      "Epoch 00043: val_PSNR improved from 33.23593 to 33.27056, saving model to C:/Users/vergi/Documents/weights\\saved-model-43.hdf5\n",
      "Epoch 44/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.6099e-04 - PSNR: 33.5859 - val_loss: 4.8973e-04 - val_PSNR: 33.2276\n",
      "\n",
      "Epoch 00044: val_PSNR did not improve from 33.27056\n",
      "Epoch 45/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5764e-04 - PSNR: 33.6168 - val_loss: 4.8746e-04 - val_PSNR: 33.2398\n",
      "\n",
      "Epoch 00045: val_PSNR did not improve from 33.27056\n",
      "Epoch 46/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5666e-04 - PSNR: 33.6192 - val_loss: 4.9319e-04 - val_PSNR: 33.1660\n",
      "\n",
      "Epoch 00046: val_PSNR did not improve from 33.27056\n",
      "Epoch 47/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5617e-04 - PSNR: 33.6290 - val_loss: 5.0663e-04 - val_PSNR: 33.0700\n",
      "\n",
      "Epoch 00047: val_PSNR did not improve from 33.27056\n",
      "Epoch 48/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5566e-04 - PSNR: 33.6359 - val_loss: 4.7829e-04 - val_PSNR: 33.2944\n",
      "\n",
      "Epoch 00048: val_PSNR improved from 33.27056 to 33.29443, saving model to C:/Users/vergi/Documents/weights\\saved-model-48.hdf5\n",
      "Epoch 49/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5393e-04 - PSNR: 33.6525 - val_loss: 4.7752e-04 - val_PSNR: 33.3411\n",
      "\n",
      "Epoch 00049: val_PSNR improved from 33.29443 to 33.34113, saving model to C:/Users/vergi/Documents/weights\\saved-model-49.hdf5\n",
      "Epoch 50/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5469e-04 - PSNR: 33.6412 - val_loss: 4.8106e-04 - val_PSNR: 33.3092\n",
      "\n",
      "Epoch 00050: val_PSNR did not improve from 33.34113\n",
      "Epoch 51/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5516e-04 - PSNR: 33.6301 - val_loss: 4.8743e-04 - val_PSNR: 33.2449\n",
      "\n",
      "Epoch 00051: val_PSNR did not improve from 33.34113\n",
      "Epoch 52/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5251e-04 - PSNR: 33.6623 - val_loss: 4.7498e-04 - val_PSNR: 33.3446\n",
      "\n",
      "Epoch 00052: val_PSNR improved from 33.34113 to 33.34460, saving model to C:/Users/vergi/Documents/weights\\saved-model-52.hdf5\n",
      "Epoch 53/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5322e-04 - PSNR: 33.6564 - val_loss: 4.8423e-04 - val_PSNR: 33.2642\n",
      "\n",
      "Epoch 00053: val_PSNR did not improve from 33.34460\n",
      "Epoch 54/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5155e-04 - PSNR: 33.6721 - val_loss: 4.8581e-04 - val_PSNR: 33.2281\n",
      "\n",
      "Epoch 00054: val_PSNR did not improve from 33.34460\n",
      "Epoch 55/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5192e-04 - PSNR: 33.6655 - val_loss: 4.8129e-04 - val_PSNR: 33.2784\n",
      "\n",
      "Epoch 00055: val_PSNR did not improve from 33.34460\n",
      "Epoch 56/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4857e-04 - PSNR: 33.7016 - val_loss: 4.7765e-04 - val_PSNR: 33.3069\n",
      "\n",
      "Epoch 00056: val_PSNR did not improve from 33.34460\n",
      "Epoch 57/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5257e-04 - PSNR: 33.6636 - val_loss: 4.8420e-04 - val_PSNR: 33.2717\n",
      "\n",
      "Epoch 00057: val_PSNR did not improve from 33.34460\n",
      "Epoch 58/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.5131e-04 - PSNR: 33.6719 - val_loss: 4.8324e-04 - val_PSNR: 33.2562\n",
      "\n",
      "Epoch 00058: val_PSNR did not improve from 33.34460\n",
      "Epoch 59/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4868e-04 - PSNR: 33.6870 - val_loss: 4.7942e-04 - val_PSNR: 33.3073\n",
      "\n",
      "Epoch 00059: val_PSNR did not improve from 33.34460\n",
      "Epoch 60/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4957e-04 - PSNR: 33.6834 - val_loss: 4.8186e-04 - val_PSNR: 33.2879\n",
      "\n",
      "Epoch 00060: val_PSNR did not improve from 33.34460\n",
      "Epoch 61/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4817e-04 - PSNR: 33.7058 - val_loss: 4.8313e-04 - val_PSNR: 33.2578\n",
      "\n",
      "Epoch 00061: val_PSNR did not improve from 33.34460\n",
      "Epoch 62/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4896e-04 - PSNR: 33.6970 - val_loss: 4.7748e-04 - val_PSNR: 33.3089\n",
      "\n",
      "Epoch 00062: val_PSNR did not improve from 33.34460\n",
      "Epoch 63/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4856e-04 - PSNR: 33.6961 - val_loss: 4.7610e-04 - val_PSNR: 33.3263\n",
      "\n",
      "Epoch 00063: val_PSNR did not improve from 33.34460\n",
      "Epoch 64/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4969e-04 - PSNR: 33.6919 - val_loss: 4.7613e-04 - val_PSNR: 33.3153\n",
      "\n",
      "Epoch 00064: val_PSNR did not improve from 33.34460\n",
      "Epoch 65/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4755e-04 - PSNR: 33.7067 - val_loss: 4.7899e-04 - val_PSNR: 33.2871\n",
      "\n",
      "Epoch 00065: val_PSNR did not improve from 33.34460\n",
      "Epoch 66/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4796e-04 - PSNR: 33.7026 - val_loss: 4.8105e-04 - val_PSNR: 33.2930\n",
      "\n",
      "Epoch 00066: val_PSNR did not improve from 33.34460\n",
      "Epoch 67/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4590e-04 - PSNR: 33.7251 - val_loss: 4.7596e-04 - val_PSNR: 33.3347\n",
      "\n",
      "Epoch 00067: val_PSNR did not improve from 33.34460\n",
      "Epoch 68/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4734e-04 - PSNR: 33.7176 - val_loss: 4.8402e-04 - val_PSNR: 33.2469\n",
      "\n",
      "Epoch 00068: val_PSNR did not improve from 33.34460\n",
      "Epoch 69/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4693e-04 - PSNR: 33.7078 - val_loss: 4.8186e-04 - val_PSNR: 33.2784\n",
      "\n",
      "Epoch 00069: val_PSNR did not improve from 33.34460\n",
      "Epoch 70/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4624e-04 - PSNR: 33.7173 - val_loss: 4.7198e-04 - val_PSNR: 33.3914\n",
      "\n",
      "Epoch 00070: val_PSNR improved from 33.34460 to 33.39140, saving model to C:/Users/vergi/Documents/weights\\saved-model-70.hdf5\n",
      "Epoch 71/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4780e-04 - PSNR: 33.7083 - val_loss: 4.7500e-04 - val_PSNR: 33.3367\n",
      "\n",
      "Epoch 00071: val_PSNR did not improve from 33.39140\n",
      "Epoch 72/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4307e-04 - PSNR: 33.7535 - val_loss: 4.7390e-04 - val_PSNR: 33.3649\n",
      "\n",
      "Epoch 00072: val_PSNR did not improve from 33.39140\n",
      "Epoch 73/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4758e-04 - PSNR: 33.7170 - val_loss: 4.7717e-04 - val_PSNR: 33.3067\n",
      "\n",
      "Epoch 00073: val_PSNR did not improve from 33.39140\n",
      "Epoch 74/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4367e-04 - PSNR: 33.7500 - val_loss: 4.8142e-04 - val_PSNR: 33.2805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_PSNR did not improve from 33.39140\n",
      "Epoch 75/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4432e-04 - PSNR: 33.7418 - val_loss: 4.8092e-04 - val_PSNR: 33.2956\n",
      "\n",
      "Epoch 00075: val_PSNR did not improve from 33.39140\n",
      "Epoch 76/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4465e-04 - PSNR: 33.7386 - val_loss: 4.7274e-04 - val_PSNR: 33.3902\n",
      "\n",
      "Epoch 00076: val_PSNR did not improve from 33.39140\n",
      "Epoch 77/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4473e-04 - PSNR: 33.7378 - val_loss: 4.8444e-04 - val_PSNR: 33.2643\n",
      "\n",
      "Epoch 00077: val_PSNR did not improve from 33.39140\n",
      "Epoch 78/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4347e-04 - PSNR: 33.7565 - val_loss: 4.8214e-04 - val_PSNR: 33.2971\n",
      "\n",
      "Epoch 00078: val_PSNR did not improve from 33.39140\n",
      "Epoch 79/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4376e-04 - PSNR: 33.7516 - val_loss: 4.7154e-04 - val_PSNR: 33.3639\n",
      "\n",
      "Epoch 00079: val_PSNR did not improve from 33.39140\n",
      "Epoch 80/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4400e-04 - PSNR: 33.7397 - val_loss: 4.7778e-04 - val_PSNR: 33.2909\n",
      "\n",
      "Epoch 00080: val_PSNR did not improve from 33.39140\n",
      "Epoch 81/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4239e-04 - PSNR: 33.7537 - val_loss: 4.7292e-04 - val_PSNR: 33.3635\n",
      "\n",
      "Epoch 00081: val_PSNR did not improve from 33.39140\n",
      "Epoch 82/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4447e-04 - PSNR: 33.7484 - val_loss: 4.6856e-04 - val_PSNR: 33.4052\n",
      "\n",
      "Epoch 00082: val_PSNR improved from 33.39140 to 33.40521, saving model to C:/Users/vergi/Documents/weights\\saved-model-82.hdf5\n",
      "Epoch 83/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4016e-04 - PSNR: 33.7831 - val_loss: 4.7001e-04 - val_PSNR: 33.3979\n",
      "\n",
      "Epoch 00083: val_PSNR did not improve from 33.40521\n",
      "Epoch 84/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4292e-04 - PSNR: 33.7558 - val_loss: 4.7550e-04 - val_PSNR: 33.3210\n",
      "\n",
      "Epoch 00084: val_PSNR did not improve from 33.40521\n",
      "Epoch 85/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4140e-04 - PSNR: 33.7658 - val_loss: 4.6880e-04 - val_PSNR: 33.3942\n",
      "\n",
      "Epoch 00085: val_PSNR did not improve from 33.40521\n",
      "Epoch 86/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4408e-04 - PSNR: 33.7427 - val_loss: 4.7215e-04 - val_PSNR: 33.3811\n",
      "\n",
      "Epoch 00086: val_PSNR did not improve from 33.40521\n",
      "Epoch 87/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4079e-04 - PSNR: 33.7763 - val_loss: 4.7262e-04 - val_PSNR: 33.3749\n",
      "\n",
      "Epoch 00087: val_PSNR did not improve from 33.40521\n",
      "Epoch 88/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4083e-04 - PSNR: 33.7783 - val_loss: 4.7072e-04 - val_PSNR: 33.3867\n",
      "\n",
      "Epoch 00088: val_PSNR did not improve from 33.40521\n",
      "Epoch 89/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4170e-04 - PSNR: 33.7698 - val_loss: 4.7472e-04 - val_PSNR: 33.3464\n",
      "\n",
      "Epoch 00089: val_PSNR did not improve from 33.40521\n",
      "Epoch 90/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4175e-04 - PSNR: 33.7635 - val_loss: 4.6902e-04 - val_PSNR: 33.3847\n",
      "\n",
      "Epoch 00090: val_PSNR did not improve from 33.40521\n",
      "Epoch 91/100\n",
      "3210/3210 [==============================] - 138s 43ms/step - loss: 4.4140e-04 - PSNR: 33.7773 - val_loss: 4.6361e-04 - val_PSNR: 33.4666\n",
      "\n",
      "Epoch 00091: val_PSNR improved from 33.40521 to 33.46658, saving model to C:/Users/vergi/Documents/weights\\saved-model-91.hdf5\n",
      "Epoch 92/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3914e-04 - PSNR: 33.7932 - val_loss: 4.7082e-04 - val_PSNR: 33.3619\n",
      "\n",
      "Epoch 00092: val_PSNR did not improve from 33.46658\n",
      "Epoch 93/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4173e-04 - PSNR: 33.7689 - val_loss: 4.7051e-04 - val_PSNR: 33.3828\n",
      "\n",
      "Epoch 00093: val_PSNR did not improve from 33.46658\n",
      "Epoch 94/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4004e-04 - PSNR: 33.7766 - val_loss: 4.7180e-04 - val_PSNR: 33.3752\n",
      "\n",
      "Epoch 00094: val_PSNR did not improve from 33.46658\n",
      "Epoch 95/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.4122e-04 - PSNR: 33.7650 - val_loss: 4.6581e-04 - val_PSNR: 33.4195\n",
      "\n",
      "Epoch 00095: val_PSNR did not improve from 33.46658\n",
      "Epoch 96/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3892e-04 - PSNR: 33.8040 - val_loss: 4.7420e-04 - val_PSNR: 33.3507\n",
      "\n",
      "Epoch 00096: val_PSNR did not improve from 33.46658\n",
      "Epoch 97/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3906e-04 - PSNR: 33.7847 - val_loss: 4.6651e-04 - val_PSNR: 33.4211\n",
      "\n",
      "Epoch 00097: val_PSNR did not improve from 33.46658\n",
      "Epoch 98/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3969e-04 - PSNR: 33.7844 - val_loss: 4.7357e-04 - val_PSNR: 33.3684\n",
      "\n",
      "Epoch 00098: val_PSNR did not improve from 33.46658\n",
      "Epoch 99/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3980e-04 - PSNR: 33.7804 - val_loss: 4.7161e-04 - val_PSNR: 33.3740\n",
      "\n",
      "Epoch 00099: val_PSNR did not improve from 33.46658\n",
      "Epoch 100/100\n",
      "3210/3210 [==============================] - 139s 43ms/step - loss: 4.3798e-04 - PSNR: 33.8008 - val_loss: 4.6867e-04 - val_PSNR: 33.4039\n",
      "\n",
      "Epoch 00100: val_PSNR did not improve from 33.46658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c1eb263f70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "model.fit_generator(train_generator(X, Xi, Y, 32), validation_data=valid_generator(X, Xi, Y, 32),\n",
    "                    validation_steps=len(X)* 0.05 // 32,\n",
    "                    steps_per_epoch=len(X) // 32, epochs=epochs, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2876b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath=\"C:/Users/vergi/Documents/weights/saved-model.hdf5\", overwrite=True, save_format=None, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76bf0bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y is ready\n",
      "X is ready\n",
      "Xi is ready\n",
      "260/260 [==============================] - 7s 16ms/step - loss: 0.0060 - PSNR: 24.0682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005964038427919149, 24.068195343017578]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathY = './Validation/Y_val/'\n",
    "pathXi = \"./Validation/Xi_val/\"\n",
    "weights_path = \"./weights/bilinear/saved-model-12.hdf5\"\n",
    "Ytemp, resolution = patch(pathY)\n",
    "Y = np.copy(Ytemp)\n",
    "Ytemp = None\n",
    "print(\"Y is ready\")\n",
    "X = mosaic(Y)\n",
    "print(\"X is ready\")\n",
    "Xitemp, resolution = patch(pathXi)\n",
    "Xi = np.copy(Xitemp)\n",
    "Xitemp = None\n",
    "print(\"Xi is ready\")\n",
    "model.load_weights(weights_path)\n",
    "model.evaluate([X / 255., Xi / 255.], Y / 255., batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e21249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict([X / 255., Xi / 255.])\n",
    "img = stitch(prediction, resolution)\n",
    "cv2.imwrite('./results/result_bilinear_nn.bmp', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcf2d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.83681414225046\n",
      "19.990974654716464\n",
      "20.623369622434417\n"
     ]
    }
   ],
   "source": [
    "#сравним с другими алгоритмами. Результат алгоритма VNG взял у одногрупника \n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_orig = cv2.imread(\"./results/Original.bmp\")\n",
    "\n",
    "img_nn = cv2.imread('./results/result_bilinear_nn.bmp')\n",
    "img_bilinear = cv2.imread(\"./results/Original_bilinear.bmp\")\n",
    "img_VNG = cv2.imread(\"./results/resultVNG.bmp\")\n",
    "\n",
    "print(cv2.PSNR(img_nn, img_orig[0:2048, 0:4160]))\n",
    "print(cv2.PSNR(img_bilinear, img_orig))\n",
    "print(cv2.PSNR(img_VNG, img_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d8809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow-gpu2)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
